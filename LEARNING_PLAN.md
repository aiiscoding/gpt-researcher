# GPT-Researcher å­¦ä¹ ç¬”è®°ï¼ˆAI ç¼–ç¨‹æ—¶ä»£ç‰ˆï¼‰

> **æ ¸å¿ƒç†å¿µï¼šä½ è´Ÿè´£"çŸ¥é“åœ¨å“ªã€ä¸ºä»€ä¹ˆã€è¦ä»€ä¹ˆ"ï¼ŒAI è´Ÿè´£"æ€ä¹ˆå†™"**
> åŸºäº v0.14.6 æºç  | ç›®æ ‡ï¼šç”¨ AI é«˜æ•ˆè¿ç»´å’ŒäºŒæ¬¡å¼€å‘

---

## å­¦ä¹ æ€è·¯è¯´æ˜

ä¼ ç»Ÿå­¦ä¹ ï¼šé€è¡Œè¯»æºç  â†’ ç†è§£å®ç° â†’ è‡ªå·±å†™ä»£ç 
AI æ—¶ä»£å­¦ä¹ ï¼š**ç†è§£æ¶æ„åœ°å›¾ â†’ æŒæ¡ä¸šåŠ¡è¯­ä¹‰ â†’ å­¦ä¼šå‘ AI ç²¾å‡†æéœ€æ±‚ â†’ ä¼šéªŒè¯ AI çš„è¾“å‡º**

ä½ ä¸éœ€è¦è®°ä½æ¯ä¸ªå‡½æ•°çš„å®ç°ç»†èŠ‚ï¼Œä½†ä½ éœ€è¦ï¼š
1. **çŸ¥é“ç³»ç»Ÿæœ‰å“ªäº›æ¨¡å—ã€æ¯ä¸ªæ¨¡å—å¹²ä»€ä¹ˆ**ï¼ˆè¿™æ ·ä½ æ‰çŸ¥é“æ”¹å“ªé‡Œï¼‰
2. **ç†è§£æ•°æ®æ€ä¹ˆæµè½¬çš„**ï¼ˆè¿™æ ·ä½ æ‰èƒ½æè¿°æ¸…æ¥šéœ€æ±‚ï¼‰
3. **æŒæ¡é…ç½®å’Œæ‰©å±•ç‚¹**ï¼ˆè¿™æ ·ä½ æ‰èƒ½ç”¨æœ€å°ä»£ä»·å®ç°å˜æ›´ï¼‰
4. **ä¼šè¯»é”™è¯¯æ—¥å¿—ã€å®šä½é—®é¢˜èŒƒå›´**ï¼ˆè¿™æ ·ä½ æ‰èƒ½ç»™ AI ç²¾å‡†çš„ä¸Šä¸‹æ–‡ï¼‰
5. **ä¼šéªŒè¯æ”¹åŠ¨æ˜¯å¦æ­£ç¡®**ï¼ˆè¿™æ ·ä½ æ‰èƒ½åˆ¤æ–­ AI çš„è¾“å‡ºè´¨é‡ï¼‰

---

# ç¬¬ä¸€éƒ¨åˆ†ï¼šå·²å®Œæˆå­¦ä¹ å†…å®¹

---

## ä¸€ã€æ¶æ„åœ°å›¾ï¼ˆå¤§è„‘ä¸­çš„ GPSï¼‰

### 1.1 ä¸€å¥è¯ç†è§£é¡¹ç›®

- [x] GPT-Researcher = **ç”¨æˆ·æé—® â†’ AI è‡ªåŠ¨æœç´¢å¤šä¸ªæ¥æº â†’ æŠ“å–å†…å®¹ â†’ åˆ†ææ•´åˆ â†’ ç”Ÿæˆç ”ç©¶æŠ¥å‘Š**
- [x] æœ¬è´¨æ˜¯ä¸€ä¸ª **LLM ç¼–æ’ç³»ç»Ÿ**ï¼Œæ ¸å¿ƒä»·å€¼æ˜¯ä¸²è”"æœç´¢-æŠ“å–-åˆ†æ-å†™ä½œ"è¿™æ¡é“¾è·¯

### 1.2 å››ä¸ªå…¥å£ï¼Œä¸€ä¸ªæ ¸å¿ƒ

```
ç”¨æˆ·æ€ä¹ˆè§¦å‘ç ”ç©¶ï¼Ÿ
â”œâ”€â”€ cli.py              â†’ å‘½ä»¤è¡Œç›´æ¥è·‘
â”œâ”€â”€ main.py             â†’ å¯åŠ¨ Web æœåŠ¡ï¼ˆFastAPI ç«¯å£8000ï¼‰
â”œâ”€â”€ Python API          â†’ from gpt_researcher import GPTResearcher
â””â”€â”€ multi_agents/main.py â†’ å¤š Agent æ¨¡å¼

æ‰€æœ‰å…¥å£æœ€ç»ˆéƒ½è°ƒç”¨ â†’ GPTResearcher ç±»ï¼ˆgpt_researcher/agent.pyï¼‰
```

### 1.3 agent.py çš„ä¸‰ä¸ªå…³é”®åŠ¨ä½œ

GPTResearcher å¯¹å¤–åªæš´éœ² 3 æ­¥ï¼š

```python
researcher = GPTResearcher(query="...", report_type="research_report")
await researcher.conduct_research()   # ç¬¬1æ­¥ï¼šæ”¶é›†ä¿¡æ¯
report = await researcher.write_report()  # ç¬¬2æ­¥ï¼šå†™æŠ¥å‘Š
# ç¬¬3æ­¥ï¼šè¾“å‡ºï¼ˆMarkdown/PDF/DOCXï¼‰
```

`__init__` åˆå§‹åŒ–é¡ºåºæ­ç¤ºäº†ä¾èµ–å…³ç³»ï¼š
```
Config â†’ Retrievers â†’ Memory(å‘é‡åµŒå…¥) â†’ å„ç§ Skill ç»„ä»¶
```
æ‰€æœ‰ Skill ç»„ä»¶éƒ½æ¥æ”¶ `self`ï¼ˆGPTResearcher å®ä¾‹ï¼‰ï¼Œå½¢æˆ**ä¸­å¿ƒè¾å°„å‹æ¶æ„**ã€‚

### 1.4 æ•°æ®æµå…¨æ™¯å›¾ï¼ˆæœ€é‡è¦çš„å¿ƒæ™ºæ¨¡å‹ï¼‰

```
"ä»€ä¹ˆæ˜¯å‘é‡æ•°æ®åº“" (ç”¨æˆ·è¾“å…¥)
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ choose_agent â”‚  è®© LLM å†³å®šç”¨ä»€ä¹ˆ"äººè®¾"æ¥ç ”ç©¶
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  ï¼ˆç”¨ SMART_LLMï¼‰
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚  åˆæ¬¡æœç´¢   â”‚  ç”¨ç¬¬ä¸€ä¸ª Retriever æœç´¢ï¼Œè·å–èƒŒæ™¯çŸ¥è¯†
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ LLM æ‹†æŸ¥è¯¢ â”‚  plan_research_outline()
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  "è¯·æŠŠè¿™ä¸ªé—®é¢˜æ‹†æˆå­é—®é¢˜"ï¼ˆç”¨ FAST_LLMï¼‰
         â”‚
         â”œâ”€â”€ "å‘é‡æ•°æ®åº“çš„æ ¸å¿ƒåŸç†æ˜¯ä»€ä¹ˆ"
         â”œâ”€â”€ "å‘é‡æ•°æ®åº“æœ‰å“ªäº›ä¸»æµäº§å“"
         â”œâ”€â”€ "å‘é‡æ•°æ®åº“çš„åº”ç”¨åœºæ™¯"
         â””â”€â”€ "ä»€ä¹ˆæ˜¯å‘é‡æ•°æ®åº“"ï¼ˆåŸæŸ¥è¯¢ä¹ŸåŠ è¿›å»ï¼‰
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   asyncio.gather å¹¶è¡Œ   â”‚  æ‰€æœ‰å­æŸ¥è¯¢åŒæ—¶è·‘ï¼ˆä¸æ’é˜Ÿï¼‰
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  æ¯ä¸ªå­æŸ¥è¯¢ç‹¬ç«‹æ‰§è¡Œ _process_sub_query()            â”‚
    â”‚                                                    â”‚
    â”‚  1. æœç´¢: _search_relevant_source_urls()           â”‚
    â”‚     â†’ éå†æ‰€æœ‰ Retrieverï¼ˆTavilyã€DuckDuckGo ç­‰ï¼‰  â”‚
    â”‚     â†’ æ¯ä¸ª Retriever.search(query, max_results=5)  â”‚
    â”‚     â†’ å»é‡ + æ‰“ä¹±é¡ºåº â†’ è¿”å› URL åˆ—è¡¨              â”‚
    â”‚                                                    â”‚
    â”‚  2. æŠ“å–: scraper_manager.browse_urls(urls)        â”‚
    â”‚     â†’ å¹¶å‘è®¿é—® URLï¼ŒæŠ“å–ç½‘é¡µå†…å®¹                     â”‚
    â”‚     â†’ MAX_SCRAPER_WORKERS=15 æ§åˆ¶å¹¶å‘æ•°             â”‚
    â”‚                                                    â”‚
    â”‚  3. å‹ç¼©: context_manager.get_similar_content...() â”‚
    â”‚     â†’ åˆ†å—(1000å­—/å—) â†’ å‘é‡åŒ– â†’ ç›¸ä¼¼åº¦è¿‡æ»¤         â”‚
    â”‚     â†’ SIMILARITY_THRESHOLD=0.35 æ§åˆ¶è¿‡æ»¤ä¸¥æ ¼åº¦       â”‚
    â”‚     â†’ åªä¿ç•™ä¸å­æŸ¥è¯¢ç›¸å…³çš„æ®µè½                       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  åˆå¹¶æ‰€æœ‰å­æŸ¥è¯¢çš„ç»“æœ     â”‚ â†’ self.context
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  source_curatorï¼ˆå¯é€‰ï¼‰ â”‚  æ¥æºè´¨é‡æ’åºï¼ˆcurate_sources=True æ—¶ï¼‰
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  write_report()        â”‚ â†’ SMART_LLM æ ¹æ® context å†™æŠ¥å‘Š
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
           æœ€ç»ˆæŠ¥å‘Š (Markdown/PDF/DOCX)
```

### 1.5 conduct_research() çš„æ•°æ®æºè·¯ç”±

`researcher.py:89-211` æ˜¯ä¸€ä¸ªå¤§è·¯ç”±å™¨ï¼Œæ ¹æ® `report_source` èµ°ä¸åŒåˆ†æ”¯ï¼š

| report_source | èµ°å“ªæ¡è·¯ | å æ¯” |
|---------------|---------|------|
| `web` | `_get_context_by_web_search()` | 90% åœºæ™¯ |
| `local` | å…ˆè¯»æœ¬åœ°æ–‡æ¡£ â†’ å†èµ°æœç´¢ | |
| `hybrid` | æœ¬åœ°æ–‡æ¡£ + ç½‘é¡µæœç´¢ â†’ åˆå¹¶ | |
| `azure` | Azure Blob åŠ è½½ â†’ å†èµ°æœç´¢ | |
| `langchain_documents` | LangChain æ–‡æ¡£å¯¹è±¡ | |
| `langchain_vectorstore` | ç›´æ¥èµ°å‘é‡åº“ | |

å¦å¤– Deep æ¨¡å¼ï¼ˆ`agent.py:348`ï¼‰ç›´æ¥ `return`ï¼Œèµ° `deep_research.py` å®Œå…¨ç‹¬ç«‹çš„åˆ†æ”¯ã€‚

### 1.6 æµæ°´çº¿å·¥å‚æ¯”å–»

| å·¥ä½ | å¯¹åº”ä»£ç  | åšä»€ä¹ˆ | æ¯”å–» |
|------|---------|--------|------|
| è°ƒåº¦å‘˜ | `agent.py` | æ€»æŒ‡æŒ¥ï¼Œä¸²è”æ‰€æœ‰æ­¥éª¤ | å·¥å‚å‚é•¿ |
| æ‹†è§£å‘˜ | `actions/query_processing.py` | æŠŠå¤§é—®é¢˜æ‹†æˆå°é—®é¢˜ | é¡¹ç›®ç»ç†æ‹†ä»»åŠ¡ |
| æœç´¢å‘˜ | `retrievers/` | å»å„ä¸ªæœç´¢å¼•æ“æ‰¾èµ„æ–™ | åŠ©ç†æœä¿¡æ¯ |
| æŠ“å–å‘˜ | `scraper/` | æŠŠç½‘é¡µå†…å®¹æ‰’ä¸‹æ¥ | åŠ©ç†æŠŠæ–‡ç« å¤å°ä¸‹æ¥ |
| ç­›é€‰å‘˜ | `context/` + `memory/` | ä»å¤§é‡å†…å®¹ä¸­ç­›é€‰ç›¸å…³çš„ | ç¼–è¾‘åˆ’é‡ç‚¹ |
| å†™ä½œå‘˜ | `skills/writer.py` | æ ¹æ®ç­›é€‰åçš„å†…å®¹å†™æŠ¥å‘Š | ä½œå®¶å†™ç¨¿ |
| é…ç½®ä¸­å¿ƒ | `config/` + `.env` | æ§åˆ¶æ‰€æœ‰äººçš„è¡Œä¸ºå‚æ•° | HRå’Œè¡Œæ”¿éƒ¨ |

### 1.7 æ¨¡å—åŠŸèƒ½é€ŸæŸ¥è¡¨

| æˆ‘æƒ³æ”¹... | å»æ‰¾... | è·¯å¾„ |
|-----------|---------|------|
| ç ”ç©¶çš„ä¸»æµç¨‹/ç¼–æ’é€»è¾‘ | GPTResearcher ç±» | `gpt_researcher/agent.py` |
| é»˜è®¤é…ç½®/å‚æ•° | DEFAULT_CONFIG | `gpt_researcher/config/variables/default.py` |
| æœç´¢ç”¨ä»€ä¹ˆå¼•æ“ | Retrievers | `gpt_researcher/retrievers/` |
| ç½‘é¡µæ€ä¹ˆæŠ“å–è§£æ | Scrapers | `gpt_researcher/scraper/` |
| æŠ¥å‘Šæ€ä¹ˆå†™çš„/å†™ä½œé£æ ¼ | Prompts | `gpt_researcher/prompts.py` |
| ç”¨å“ªä¸ª LLM/æ€ä¹ˆè°ƒç”¨ | LLM Provider | `gpt_researcher/llm_provider/` |
| ä¸Šä¸‹æ–‡æ€ä¹ˆç­›é€‰å‹ç¼© | Context | `gpt_researcher/context/` |
| å‘é‡åµŒå…¥/è¯­ä¹‰æœç´¢ | Memory | `gpt_researcher/memory/` |
| æ·±åº¦ç ”ç©¶æ¨¡å¼ | DeepResearch | `gpt_researcher/skills/deep_research.py` |
| MCP å·¥å…·æ‰©å±• | MCP | `gpt_researcher/mcp/` |
| å¤š Agent åä½œæ¨¡å¼ | Multi-Agents | `multi_agents/` |
| Web API æ¥å£ | Backend | `backend/server/` |
| å‰ç«¯ UI | Frontend | `frontend/nextjs/` |
| éƒ¨ç½²é…ç½® | Docker/Terraform | æ ¹ç›®å½• `Dockerfile`, `terraform/` |

---

## äºŒã€é…ç½®å³æ§åˆ¶

### 2.1 é…ç½®åŠ è½½æœºåˆ¶

`config.py:62-75` çš„æ ¸å¿ƒé€»è¾‘ï¼š

```python
for key, value in config.items():
    env_value = os.getenv(key)        # å…ˆçœ‹ç¯å¢ƒå˜é‡æœ‰æ²¡æœ‰
    if env_value is not None:
        value = self.convert_env_value(...)  # æœ‰å°±ç”¨ç¯å¢ƒå˜é‡çš„
    setattr(self, key.lower(), value)  # è®¾åˆ° self ä¸Šï¼Œkey å˜å°å†™
```

**ä¼˜å…ˆçº§ï¼šç¯å¢ƒå˜é‡ > JSON é…ç½®æ–‡ä»¶ > DEFAULT_CONFIG é»˜è®¤å€¼**

### 2.2 é…ç½®é¡¹é€ŸæŸ¥

| ç±»åˆ« | é…ç½®é¡¹ | é»˜è®¤å€¼ | ä½ è¦çŸ¥é“çš„ |
|------|--------|--------|-----------|
| **LLM** | `FAST_LLM` | `openai:gpt-4o-mini` | å¿«é€Ÿä»»åŠ¡ï¼Œä¾¿å®œ |
| | `SMART_LLM` | `openai:gpt-4.1` | æŠ¥å‘Šå†™ä½œï¼Œè´¨é‡å¥½ |
| | `STRATEGIC_LLM` | `openai:o4-mini` | å¤æ‚æ¨ç†ï¼Œæœ€è´µ |
| **æœç´¢** | `RETRIEVER` | `tavily` | 14 ç§å¯é€‰ï¼Œé€—å·åˆ†éš”å¯æ··åˆ |
| | `MAX_SEARCH_RESULTS_PER_QUERY` | `5` | æ¯ä¸ªå­æŸ¥è¯¢å–å¤šå°‘æ¡ |
| **æŠ“å–** | `SCRAPER` | `bs` | bs/browser/pymupdf/firecrawl |
| | `MAX_SCRAPER_WORKERS` | `15` | å¹¶å‘æŠ“å–æ•° |
| **å‹ç¼©** | `SIMILARITY_THRESHOLD` | `0.35`ï¼ˆä»£ç ï¼‰/ `0.42`ï¼ˆé…ç½®ï¼‰ | å‘é‡ç›¸ä¼¼åº¦è¿‡æ»¤é˜ˆå€¼ |
| | `EMBEDDING` | `openai:text-embedding-3-small` | å‘é‡åµŒå…¥æ¨¡å‹ |
| **æŠ¥å‘Š** | `REPORT_TYPE` | `research_report` | 7 ç§ç±»å‹ |
| | `TOTAL_WORDS` | `1200` | æŠ¥å‘Šå­—æ•° |
| | `TEMPERATURE` | `0.4` | LLM åˆ›é€ æ€§ |
| | `LANGUAGE` | `english` | è¾“å‡ºè¯­è¨€ |
| **æ·±åº¦ç ”ç©¶** | `DEEP_RESEARCH_BREADTH` | `3` | å¹¿åº¦ |
| | `DEEP_RESEARCH_DEPTH` | `2` | æ·±åº¦ |
| | `DEEP_RESEARCH_CONCURRENCY` | `4` | å¹¶å‘ |
| **å…¶ä»–** | `MAX_SUBTOPICS` | `3` | å­æŸ¥è¯¢æ‹†åˆ†æ•°é‡ä¸Šé™ |
| | `PROMPT_FAMILY` | `default` | æç¤ºè¯é£æ ¼æ— |
| | `CURATE_SOURCES` | `False` | æ˜¯å¦å¯ç”¨æ¥æºæ’åº |

### 2.3 é…ç½®å®éªŒæ‰‹å†Œ

æ‰€æœ‰å®éªŒåŸºäºå‘½ä»¤ï¼š
```bash
python cli.py "ä»€ä¹ˆæ˜¯å‘é‡æ•°æ®åº“" --report_type research_report --no-pdf --no-docx
```

| å®éªŒ | æ”¹ä»€ä¹ˆ | å‘½ä»¤å‰ç¼€ | è§‚å¯Ÿä»€ä¹ˆ |
|------|--------|---------|---------|
| **åˆ‡æ¢æœç´¢å¼•æ“** | `RETRIEVER` | `RETRIEVER=duckduckgo` | URL æ¥æºå·®å¼‚ã€ç»“æœè´¨é‡ |
| **è°ƒæœç´¢ç»“æœæ•°** | `MAX_SEARCH_RESULTS_PER_QUERY` | `MAX_SEARCH_RESULTS_PER_QUERY=2` vs `=10` | ä¸°å¯Œåº¦ vs é€Ÿåº¦ |
| **åˆ‡æ¢å†™ä½œæ¨¡å‹** | `SMART_LLM` | `SMART_LLM=openai:gpt-4o-mini` | æŠ¥å‘Šè´¨é‡ vs æˆæœ¬ |
| **æ§åˆ¶æŠ¥å‘Šé•¿åº¦** | `TOTAL_WORDS` + `MAX_SUBTOPICS` | `TOTAL_WORDS=500 MAX_SUBTOPICS=2` | æ·±åº¦ vs é€Ÿåº¦ |
| **ä¸åŒæŠ¥å‘Šç±»å‹** | `--report_type` | åˆ†åˆ«è·‘ `research_report`/`outline_report`/`resource_report` | è¾“å‡ºæ ¼å¼å·®å¼‚ |

**æ ¸å¿ƒç›´è§‰ï¼š**
```
æƒ³çœé’±ï¼Ÿ       â†’ SMART_LLM é™çº§, MAX_SEARCH_RESULTS å‡å°‘
æƒ³æ›´å¿«ï¼Ÿ       â†’ report_type ç”¨ outline, TOTAL_WORDS å‡å°‘
æƒ³æ›´å…¨é¢ï¼Ÿ     â†’ MAX_SEARCH_RESULTS è°ƒå¤§, MAX_SUBTOPICS è°ƒå¤§
æƒ³æ›´é«˜è´¨é‡ï¼Ÿ   â†’ SMART_LLM å‡çº§, RETRIEVER ç”¨ tavily
æƒ³é™å®šæ¥æºï¼Ÿ   â†’ --query_domains æŒ‡å®šåŸŸå
æƒ³è¾“å‡ºä¸­æ–‡ï¼Ÿ   â†’ LANGUAGE=chinese
```

---

## ä¸‰ã€ä¸Šä¸‹æ–‡å‹ç¼©æœºåˆ¶ï¼ˆæŠ¥å‘Šè´¨é‡çš„å…³é”®ï¼‰

### 3.1 ä¸ºä»€ä¹ˆéœ€è¦å‹ç¼©

æŠ“å– 5 ä¸ªç½‘é¡µå¯èƒ½äº§ç”Ÿ 5-10 ä¸‡å­—åŸå§‹å†…å®¹ï¼Œä½† LLM ä¸Šä¸‹æ–‡çª—å£æœ‰é™ä¸” 90% æ˜¯å™ªéŸ³ï¼ˆå¯¼èˆªæ ã€å¹¿å‘Šã€æ— å…³æ®µè½ï¼‰ã€‚å–‚å¤ªå¤šåƒåœ¾è¿›å»æŠ¥å‘Šè´¨é‡åè€Œå·®ã€‚

### 3.2 å‹ç¼©ç®¡é“ï¼šä¸‰æ­¥æµæ°´çº¿

```
ç¬¬ 1 æ­¥ï¼šåˆ†å— (RecursiveCharacterTextSplitter)
   åŸå§‹ç½‘é¡µï¼ˆå‡ ä¸‡å­—ï¼‰â†’ åˆ‡æˆ 1000 å­—ä¸€å—ï¼Œç›¸é‚»å— 100 å­—é‡å 
   â†’ è¾“å‡º: [chunk1, chunk2, ... chunk50]

ç¬¬ 2 æ­¥ï¼šå‘é‡ç›¸ä¼¼åº¦è¿‡æ»¤ (EmbeddingsFilter)
   æŸ¥è¯¢ "å‘é‡æ•°æ®åº“çš„æ ¸å¿ƒåŸç†" â†’ Embedding æ¨¡å‹ â†’ [0.12, -0.34, 0.56, ...]
   æ¯ä¸ª chunk â†’ Embedding æ¨¡å‹ â†’ [å‘é‡]
   è®¡ç®— cosine ç›¸ä¼¼åº¦ â†’ åªä¿ç•™ > SIMILARITY_THRESHOLD çš„ chunk
   â†’ 50 ä¸ª chunk å¯èƒ½åªå‰© 5-8 ä¸ª

ç¬¬ 3 æ­¥ï¼šæ ¼å¼åŒ–è¾“å‡º (pretty_print_docs)
   ç­›é€‰åçš„ chunk â†’ æ‹¼æ¥ + é™„ä¸Šæ¥æº URL â†’ è¾“å‡ºç»™ LLM å†™æŠ¥å‘Š
```

ä»£ç ä½ç½®ï¼š`compression.py:121-140`

### 3.3 å‘é‡åµŒå…¥ 30 ç§’ç†è§£

```
"å‘é‡æ•°æ®åº“çš„æ ¸å¿ƒåŸç†"    â†’ [0.12, -0.34, 0.56, ...]  (1536ç»´)
"å‘é‡æ£€ç´¢ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦"  â†’ [0.11, -0.32, 0.55, ...]  â† å¾ˆæ¥è¿‘ï¼ç›¸ä¼¼åº¦ 0.92
"ä»Šå¤©å¤©æ°”çœŸå¥½"            â†’ [0.87, 0.22, -0.63, ...]  â† å·®å¾ˆè¿œï¼ç›¸ä¼¼åº¦ 0.08
```

**æœ¬è´¨ï¼šæŠŠæ–‡å­—å˜æˆæ•°å­—åˆ—è¡¨ï¼Œè¯­ä¹‰ç›¸è¿‘çš„æ–‡å­—æ•°å­—ä¹Ÿç›¸è¿‘ã€‚**

### 3.4 ä¸‰ä¸ªè°ƒèŠ‚æ—‹é’®

| å‚æ•° | ä»£ç ä½ç½® | é»˜è®¤ | ä½œç”¨ |
|------|---------|------|------|
| `chunk_size` | `compression.py:128` | 1000 | æ¯å—å¤šå¤§ |
| `chunk_overlap` | `compression.py:128` | 100 | ç›¸é‚»å—é‡å  |
| `SIMILARITY_THRESHOLD` | `compression.py:118` | 0.35 | **æœ€å…³é”®** |

SIMILARITY_THRESHOLD æ•ˆæœç›´è§‰ï¼š
```
0.2  â†’ å‡ ä¹å…¨ç•™ï¼ˆå®½æ¾ï¼‰â†’ å†…å®¹å¤šä½†å™ªéŸ³ä¹Ÿå¤š
0.35 â†’ é»˜è®¤å€¼ï¼ˆå¹³è¡¡ï¼‰
0.5  â†’ æ¯”è¾ƒä¸¥æ ¼ â†’ åªç•™é«˜åº¦ç›¸å…³æ®µè½
0.7  â†’ éå¸¸ä¸¥æ ¼ â†’ å¯èƒ½è¯¯æ€æœ‰ä»·å€¼å†…å®¹
```

**å®é™…åœºæ™¯è°ƒèŠ‚ï¼š**
- æŠ¥å‘Šå†…å®¹å¤ªå°‘/å¤ªæµ…ï¼Ÿ â†’ é˜ˆå€¼è°ƒä½ï¼ˆ0.2-0.3ï¼‰
- æŠ¥å‘ŠåºŸè¯å¤ªå¤š/è·‘é¢˜ï¼Ÿ â†’ é˜ˆå€¼è°ƒé«˜ï¼ˆ0.45-0.55ï¼‰
- ä¸­æ–‡æŸ¥è¯¢ + è‹±æ–‡ç½‘é¡µï¼Ÿ â†’ è·¨è¯­è¨€ç›¸ä¼¼åº¦å¤©ç„¶ä½ï¼Œé˜ˆå€¼å¿…é¡»è°ƒä½

### 3.5 Memory ç±»

`memory/embeddings.py` æ˜¯ä¸€ä¸ªçº¯ç²¹çš„ **Embedding ä¾›åº”å•†é€‰æ‹©å™¨**ï¼Œæ”¯æŒ 17 ç§ä¾›åº”å•†ï¼Œæ¥å£å®Œå…¨ç»Ÿä¸€ã€‚æ¢ä¾›åº”å•†åªéœ€æ”¹ `.env`ï¼š
```bash
EMBEDDING=openai:text-embedding-3-small   # ä»˜è´¹ï¼Œè´¨é‡æœ€å¥½
EMBEDDING=ollama:nomic-embed-text         # æœ¬åœ°å…è´¹
```

---

## å››ã€æ•…éšœæ’æŸ¥å®æˆ˜æ‰‹å†Œ

### 4.1 æ—¥å¿—é˜¶æ®µæ ‡å¿—ï¼ˆå®šä½é—®é¢˜çš„ç¬¬ä¸€æ­¥ï¼‰

```
"ğŸ” Starting the research task..."     â†’ åˆšè¿›å…¥æµæ°´çº¿
"ğŸŒ Browsing the web..."              â†’ è¿›å…¥æœç´¢é˜¶æ®µ
"ğŸ¤” Planning the research strategy..." â†’ è¿›å…¥æŸ¥è¯¢è§„åˆ’
"ğŸ—‚ï¸ I will conduct my research..."     â†’ å­æŸ¥è¯¢å·²ç”Ÿæˆ
"ğŸ” Running research for 'å­æŸ¥è¯¢'..."   â†’ æ­£åœ¨æ‰§è¡Œå­æŸ¥è¯¢
"ğŸ¤” Researching for relevant info..."  â†’ æ­£åœ¨æŠ“å–
"ğŸ“š Getting relevant content..."       â†’ æ­£åœ¨ä¸Šä¸‹æ–‡å‹ç¼©
"ğŸ’¸ Total Research Costs: $xxx"        â†’ ç ”ç©¶é˜¶æ®µå®Œæˆ
æŠ¥å‘Šå†…å®¹è¾“å‡º                            â†’ å†™ä½œé˜¶æ®µå®Œæˆ
```

**æ—¥å¿—åœåœ¨å“ªé‡Œï¼Œé—®é¢˜å°±åœ¨é‚£ä¸€æ­¥ã€‚**

### 4.2 åœºæ™¯ 1ï¼šç”¨æˆ·ç‚¹å‡»"å¼€å§‹ç ”ç©¶"ï¼Œé¡µé¢å®Œå…¨æ— ååº”

**ç°è±¡ï¼š** å‰ç«¯ç‚¹äº†æŒ‰é’®ä»€ä¹ˆéƒ½æ²¡å‘ç”Ÿï¼Œæ§åˆ¶å°ä¹Ÿæ²¡æ—¥å¿—

**æ’æŸ¥ï¼š**
```
é¡µé¢æ— ååº”
â”œâ”€â”€ æµè§ˆå™¨ F12 â†’ Network é¢æ¿ â†’ æœ‰æ²¡æœ‰è¯·æ±‚å‘å‡ºå»ï¼Ÿ
â”‚
â”œâ”€â”€ æ²¡æœ‰è¯·æ±‚ â†’ å‰ç«¯é—®é¢˜
â”‚   â†’ æ£€æŸ¥ NEXT_PUBLIC_GPTR_API_URL æ˜¯å¦æŒ‡å‘æ­£ç¡®åç«¯åœ°å€
â”‚   â†’ çœ‹ frontend/nextjs/ çš„ WebSocket é…ç½®
â”‚
â””â”€â”€ è¯·æ±‚å‘äº†ä½†æ²¡å“åº” â†’ åç«¯é—®é¢˜
    â†’ main.py æ˜¯å¦å¯åŠ¨ï¼Ÿç«¯å£æ˜¯å¦æ­£ç¡®ï¼Ÿ
```

**å®šä½ï¼š** å¡åœ¨åŸºç¡€è®¾æ–½å±‚ï¼Œ**æ ¹æœ¬æ²¡è¿›å…¥ç ”ç©¶æµæ°´çº¿**ã€‚

### 4.3 åœºæ™¯ 2ï¼šå¡åœ¨ "Planning the research strategy" ä¸åŠ¨äº†

**ç°è±¡ï¼š** çœ‹åˆ° "ğŸŒ Browsing the web..." ä¹‹åç­‰ 5 åˆ†é’Ÿæ²¡åŠ¨

**æ’æŸ¥ï¼š**
```
å¡åœ¨ planning é˜¶æ®µï¼ˆresearcher.py:48-87ï¼‰
â”‚
â”‚  è¿™ä¸ªé˜¶æ®µåšä¸¤ä»¶äº‹ï¼š
â”‚    1. get_search_results()  â†’ ç”¨ Retriever æœç´¢
â”‚    2. plan_research_outline() â†’ è®© LLM æ‹†å­æŸ¥è¯¢
â”‚
â”œâ”€â”€ "ğŸŒ" ä¹‹åæ²¡å‡ºç° "ğŸ¤”" â†’ å¡åœ¨æœç´¢
â”‚   â†’ Retriever API æ— å“åº”ï¼ˆç½‘ç»œ/API Key/æœåŠ¡ä¸å¯ç”¨ï¼‰
â”‚   â†’ æ£€æŸ¥ TAVILY_API_KEY æˆ– RETRIEVER é…ç½®
â”‚
â””â”€â”€ "ğŸ¤”" å‡ºç°äº†ä½†æ²¡ä¸‹æ–‡ â†’ å¡åœ¨ LLM è°ƒç”¨
    â†’ OPENAI_API_KEY æ— æ•ˆ/é¢åº¦ä¸è¶³/ç½‘ç»œé—®é¢˜
```

### 4.4 åœºæ™¯ 3ï¼šæœç´¢æŠ“å–æ­£å¸¸ï¼Œä½†æŠ¥å‘Šå‡ ä¹ä¸ºç©º

**ç°è±¡ï¼š** æ—¥å¿—çœ‹èµ·æ¥ä¸€åˆ‡æ­£å¸¸ï¼ŒURL æœåˆ°äº†ä¹ŸæŠ“äº†ï¼Œä½†æŠ¥å‘Šåªæœ‰ä¸¤ä¸‰å¥è¯

**æ’æŸ¥ï¼š**
```
æœç´¢ âœ“ â†’ æŠ“å– âœ“ â†’ å‹ç¼© ? â†’ å†™ä½œ ?
â”‚
â”œâ”€â”€ æœ€å¤§æ¦‚ç‡ï¼šä¸Šä¸‹æ–‡å‹ç¼©æŠŠæ‰€æœ‰å†…å®¹éƒ½è¿‡æ»¤æ‰äº†
â”‚   â†’ SIMILARITY_THRESHOLD å¤ªé«˜
â”‚   â†’ ç‰¹åˆ«æ˜¯ä¸­æ–‡æŸ¥è¯¢ + è‹±æ–‡ç½‘é¡µï¼ˆè·¨è¯­è¨€ç›¸ä¼¼åº¦å¤©ç„¶ä½ï¼‰
â”‚   â†’ è§£å†³ï¼šSIMILARITY_THRESHOLD é™åˆ° 0.2
â”‚
â”œâ”€â”€ æŠ“å–å†…å®¹æœ¬èº«æ˜¯ç©ºçš„
â”‚   â†’ ç½‘é¡µåçˆ¬ï¼Œraw_content æ˜¯ç©ºå­—ç¬¦ä¸²
â”‚   â†’ è§£å†³ï¼šSCRAPER=browser æˆ– firecrawl
â”‚
â””â”€â”€ LLM å†™æŠ¥å‘Šæ—¶"å·æ‡’"
    â†’ context æœ‰äº†ä½† LLM æ²¡å……åˆ†åˆ©ç”¨
    â†’ è§£å†³ï¼šæ¢æ›´å¥½çš„ SMART_LLM æˆ–è°ƒæ•´ TOTAL_WORDS
```

### 4.5 åœºæ™¯ 4ï¼šæŠ¥å‘Šæ¥æºå…¨æ˜¯åŒä¸€ä¸ªç½‘ç«™

**ç°è±¡ï¼š** æŠ¥å‘Šå¼•ç”¨æ¥æºå…¨é›†ä¸­åœ¨ä¸€ä¸ªåŸŸå

**æ’æŸ¥ï¼š**
```
æ¥æºå•ä¸€
â”‚
â”œâ”€â”€ æœç´¢ç»“æœå°±é›†ä¸­ â†’ Retriever å¯¹è¯¥æŸ¥è¯¢è¿”å›äº†é›†ä¸­ç»“æœ
â”‚   â”œâ”€â”€ è§£å†³ 1ï¼šMAX_SEARCH_RESULTS_PER_QUERY è°ƒå¤§ï¼ˆ5â†’10ï¼‰
â”‚   â”œâ”€â”€ è§£å†³ 2ï¼šRETRIEVER=tavily,duckduckgoï¼ˆæ··åˆå¤šä¸ªå¼•æ“ï¼‰
â”‚   â””â”€â”€ è§£å†³ 3ï¼šMAX_SUBTOPICS è°ƒå¤§ï¼ˆæ›´å¤šæœç´¢è§’åº¦ï¼‰
â”‚
â””â”€â”€ åªæœ‰ä¸€ä¸ªç«™æŠ“æˆåŠŸäº† â†’ å…¶ä»–ç«™åçˆ¬å¤±è´¥
    â†’ çœ‹æ—¥å¿—æœ‰æ²¡æœ‰ scraping warning
    â†’ è§£å†³ï¼šSCRAPER=browser
```

### 4.6 åœºæ™¯ 5ï¼šDeep æ¨¡å¼ 429 Rate Limit Exceeded

**ç°è±¡ï¼š** deep æ¨¡å¼è·‘åˆ°ä¸€åŠæŠ¥ 429 Too Many Requests

**æ’æŸ¥ï¼š**
```
æ™®é€šæ¨¡å¼ï¼š~4 å­æŸ¥è¯¢ Ã— 1 è½® = ~4 æ¬¡æœç´¢ + ~4 æ¬¡ LLM
Deep æ¨¡å¼ï¼š3(breadth) Ã— 2(depth) Ã— 4(concurrency) = 20-30 æ¬¡å¹¶å‘

429 æ¥è‡ªå“ªä¸ª APIï¼Ÿ
â”œâ”€â”€ LLM API â†’ é™ä½ DEEP_RESEARCH_CONCURRENCYï¼ˆ4â†’2ï¼‰
â”œâ”€â”€ æœç´¢ API â†’ å‡çº§ Tavily æˆ–æ··åˆå…è´¹ Retriever
â””â”€â”€ Embedding API â†’ æ¢æœ¬åœ° Embeddingï¼ˆEMBEDDING=ollama:...ï¼‰
```

### 4.7 åœºæ™¯ 6ï¼šæŠ¥å‘Šå…¨æ˜¯è‹±æ–‡ï¼Œç”¨æˆ·æƒ³è¦ä¸­æ–‡

**ç°è±¡ï¼š** ä¸­æ–‡æé—®ï¼ŒæŠ¥å‘Šå´æ˜¯è‹±æ–‡

**æ’æŸ¥ï¼š**
```
â†’ default.py:28 â†’ LANGUAGE = "english"ï¼ˆé»˜è®¤è‹±æ–‡ï¼ï¼‰
â†’ .env é‡ŒåŠ  LANGUAGE=chinese å°±è¡Œ
â†’ å¦‚æœè¿˜ä¸è¡Œï¼Œé…åˆ --query_domains é™åˆ¶ä¸­æ–‡ç½‘ç«™
```

### 4.8 å¸¸è§æ•…éšœé…ç½®é€ŸæŸ¥è¡¨

| æ•…éšœç°è±¡ | æœ€å¯èƒ½çš„åŸå›  | æ”¹ä»€ä¹ˆ |
|----------|------------|--------|
| å®Œå…¨æ— ååº” | åç«¯æ²¡å¯åŠ¨/ç«¯å£é”™ | `NEXT_PUBLIC_GPTR_API_URL` |
| æœç´¢å¡ä½ | API Key æ— æ•ˆ/è¿‡æœŸ | `TAVILY_API_KEY` æˆ– `RETRIEVER` |
| LLM è°ƒç”¨å¤±è´¥ | Key/é¢åº¦/æ¨¡å‹åé”™ | `OPENAI_API_KEY`ã€`SMART_LLM` |
| æŠ¥å‘Šå†…å®¹ç©º | å‹ç¼©é˜ˆå€¼å¤ªé«˜ | `SIMILARITY_THRESHOLD` è°ƒä½ |
| æŠ¥å‘Šè·‘é¢˜ | å‹ç¼©é˜ˆå€¼å¤ªä½ | `SIMILARITY_THRESHOLD` è°ƒé«˜ |
| æ¥æºä¸å¤Ÿå¤šå…ƒ | æœç´¢ç»“æœå¤ªå°‘ | `MAX_SEARCH_RESULTS_PER_QUERY` è°ƒå¤§ |
| 429 é™æµ | å¹¶å‘å¤ªé«˜ | `DEEP_RESEARCH_CONCURRENCY` è°ƒä½ |
| è¾“å‡ºè¯­è¨€ä¸å¯¹ | è¯­è¨€é…ç½® | `LANGUAGE=chinese` |
| æŠ“å–å†…å®¹ä¸ºç©º | ç½‘ç«™åçˆ¬ | `SCRAPER=browser` |
| æŠ¥å‘Šå¤ªçŸ­ | å­—æ•°é…ç½® | `TOTAL_WORDS` è°ƒå¤§ |

### 4.9 æ’æŸ¥æ–¹æ³•è®º

```
ç¬¬ä¸€æ­¥ï¼šçœ‹æ—¥å¿—åœåœ¨å“ªé‡Œ â†’ å®šä½é˜¶æ®µ
ç¬¬äºŒæ­¥ï¼šåˆ¤æ–­æ˜¯é…ç½®é—®é¢˜è¿˜æ˜¯ä»£ç é—®é¢˜
        é…ç½®é—®é¢˜ï¼ˆ80%ï¼‰â†’ è‡ªå·±æ”¹ .env
        ä»£ç é—®é¢˜ï¼ˆ20%ï¼‰â†’ å‘Šè¯‰ AI ä¸‰ä»¶äº‹ï¼š
          1. å¡åœ¨å“ªä¸ªé˜¶æ®µï¼ˆä»æ—¥å¿—åˆ¤æ–­ï¼‰
          2. æŠ¥äº†ä»€ä¹ˆé”™ï¼ˆè´´é”™è¯¯æ—¥å¿—ï¼‰
          3. ç›¸å…³ä»£ç åœ¨å“ªä¸ªç›®å½•ï¼ˆä»æ¨¡å—é€ŸæŸ¥è¡¨å®šä½ï¼‰
```

---

## äº”ã€AI åä½œå…ƒæŠ€èƒ½

### 5.1 å‘ AI æè¿°éœ€æ±‚çš„æ¨¡æ¿

```markdown
## éœ€æ±‚
[ä¸€å¥è¯è¯´æ¸…æ¥šè¦åšä»€ä¹ˆ]

## ä¸Šä¸‹æ–‡
- é¡¹ç›®ï¼šGPT-Researcher
- ç›¸å…³æ¨¡å—ï¼š[ä»æ¨¡å—é€ŸæŸ¥è¡¨å®šä½]
- ç›¸å…³æ–‡ä»¶ï¼š[å…·ä½“æ–‡ä»¶è·¯å¾„]

## çº¦æŸ
- [ä¸è¦æ”¹åŠ¨å“ªäº›æ–‡ä»¶]
- [è¦å…¼å®¹å“ªäº›ç°æœ‰åŠŸèƒ½]
- [æ€§èƒ½/æˆæœ¬è¦æ±‚]

## å‚è€ƒ
- å‚è€ƒç°æœ‰çš„ [xxx] å®ç°æ–¹å¼
```

### 5.2 é«˜æ•ˆ vs ä½æ•ˆ Prompt å¯¹æ¯”

| åœºæ™¯ | ä½æ•ˆ | é«˜æ•ˆ |
|------|------|------|
| åŠ åŠŸèƒ½ | "å¸®æˆ‘åŠ ä¸ªæœç´¢å¼•æ“" | "å¸®æˆ‘åœ¨ `retrievers/` ä¸‹æ–°å»º `my_search/`ï¼Œå®ç° CustomRetriever æ¥å£ï¼Œæ¥å…¥ xxx API" |
| æ”¹ Bug | "æŠ¥å‘Šç”Ÿæˆæœ‰é—®é¢˜" | "æŠ¥å‘Šç”Ÿæˆæ—¶ `report_generation.py:L120` é™„è¿‘å¼•ç”¨æ ¼å¼ä¸å¯¹ï¼Œåº”è¯¥æ˜¯ APA ä½†è¾“å‡º MLA" |
| ç†è§£ä»£ç  | "è§£é‡Šä¸€ä¸‹è¿™ä¸ªé¡¹ç›®" | "è§£é‡Š `agent.py` ä¸­ `conduct_research()` çš„æ‰§è¡Œæµç¨‹ï¼Œé‡ç‚¹è¯´æ˜ Retriever å¦‚ä½•è¢«è°ƒåº¦" |
| æ’éšœ | "è·‘ä¸èµ·æ¥äº†" | "å¯åŠ¨ `main.py` æŠ¥é”™ [é”™è¯¯ä¿¡æ¯]ï¼Œ`.env` é…ç½®æ˜¯ [é…ç½®]ï¼Œå¸®æˆ‘æ’æŸ¥" |
| æ”¹é…ç½® | "è®©æŠ¥å‘Šå¥½ä¸€ç‚¹" | "å¸®æˆ‘æŠŠ SIMILARITY_THRESHOLD ä» 0.35 é™åˆ° 0.25ï¼Œä¸­æ–‡æŸ¥è¯¢è‹±æ–‡ç½‘é¡µç›¸ä¼¼åº¦å¤ªä½" |
| æ‰©å±•åŠŸèƒ½ | "èƒ½ä¸èƒ½åŠ ä¸ªç¿»è¯‘" | "å¸®æˆ‘åœ¨å¤š Agent æµç¨‹ Writer å’Œ Publisher ä¹‹é—´åŠ ä¸€ä¸ªç¿»è¯‘ Agentï¼Œå‚è€ƒ `multi_agents/agents/` ä¸‹çš„å†™æ³•" |

### 5.3 éªŒè¯ AI è¾“å‡ºçš„æ£€æŸ¥æ¸…å•

- [ ] **åŠŸèƒ½æ­£ç¡®æ€§**ï¼šæ”¹åŠ¨æ˜¯å¦è§£å†³äº†éœ€æ±‚ï¼Ÿ
- [ ] **å½±å“èŒƒå›´**ï¼šæ”¹äº†å“ªäº›æ–‡ä»¶ï¼Ÿæœ‰æ²¡æœ‰æ„å¤–ä¿®æ”¹å…¶ä»–æ¨¡å—ï¼Ÿ
- [ ] **é…ç½®å…¼å®¹**ï¼šæ–°ä»£ç æ˜¯å¦éµå¾ª Config ç³»ç»Ÿçš„çº¦å®šï¼Ÿ
- [ ] **æ¥å£ä¸€è‡´**ï¼šæ–°æ¨¡å—çš„è¾“å…¥è¾“å‡ºæ˜¯å¦ä¸ä¸Šä¸‹æ¸¸å…¼å®¹ï¼Ÿ
- [ ] **é”™è¯¯å¤„ç†**ï¼šè¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸æ˜¯å¦æœ‰å¤„ç†ï¼Ÿ
- [ ] **å¯å›æ»š**ï¼šgit commit äº†å—ï¼Ÿå‡ºé—®é¢˜èƒ½å¿«é€Ÿå›é€€ï¼Ÿ

---

## å…­ã€å…³é”®æ¶æ„ç»†èŠ‚è¡¥å……

### 6.1 å¹¶è¡Œæ‰§è¡Œæ¨¡å‹

```python
# researcher.py:347-354
context = await asyncio.gather(
    *[self._process_sub_query(sub_query, ...) for sub_query in sub_queries]
)
```

æ‰€æœ‰å­æŸ¥è¯¢å¹¶è¡Œæ‰§è¡Œã€‚æ€§èƒ½ç“¶é¢ˆä¸åœ¨å­æŸ¥è¯¢æ•°é‡ï¼Œåœ¨**å•ä¸ªå­æŸ¥è¯¢å†…çš„æŠ“å–é€Ÿåº¦**ï¼ˆ`MAX_SCRAPER_WORKERS`ï¼‰ã€‚

### 6.2 ä¸‰çº§ LLM åœ¨æµæ°´çº¿ä¸­çš„ä½ç½®

| æ­¥éª¤ | ç”¨å“ªä¸ª LLM | ä¸ºä»€ä¹ˆ |
|------|-----------|--------|
| choose_agent() | SMART_LLM | éœ€è¦ç†è§£æŸ¥è¯¢æ„å›¾ |
| å­æŸ¥è¯¢ç”Ÿæˆ | FAST_LLM | ç®€å•æ‹†åˆ†ä»»åŠ¡ |
| æŠ¥å‘Šå†™ä½œ | SMART_LLM | éœ€è¦å†™ä½œè´¨é‡ |
| å¤æ‚æ¨ç†/è§„åˆ’ | STRATEGIC_LLM | éœ€è¦æ·±åº¦æ€è€ƒ |

### 6.3 å…­å¤§æ‰©å±•ç‚¹

| æ‰©å±•ç‚¹ | æ¥å£ | ä½ç½® | æ€ä¹ˆåŠ  |
|--------|------|------|--------|
| æ–°æœç´¢å¼•æ“ | `search(query, max_results) â†’ List[Dict]` | `retrievers/` | ç»§æ‰¿ CustomRetriever |
| æ–°æŠ“å–å™¨ | è¾“å…¥ URL â†’ è¾“å‡ºçº¯æ–‡æœ¬ | `scraper/` | æ–°å»ºå­ç›®å½• |
| æ–° LLM | `provider:model` è¯­æ³• | `.env` | LangChain æ”¯æŒå³å¯ç”¨ |
| æ–°æç¤ºè¯ | `PROMPT_FAMILY` é…ç½® | `prompts.py` | è‡ªå®šä¹‰ family |
| æ–°æŠ¥å‘Šç±»å‹ | æ¯ç±»å‹ä¸€ä¸ª Agent | `backend/report_type/` | æ–°å»ºæ–‡ä»¶ |
| MCP å·¥å…· | MCP Server é…ç½® | `mcp/` | é…ç½® JSON å³å¯ |

### 6.4 å¤š Agent æ¨¡å¼æ¦‚è§ˆ

```
å• Agent æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ï¼šGPTResearcher ä¸€ä¸ªäººå¹²æ‰€æœ‰äº‹

å¤š Agent æ¨¡å¼ï¼ˆLangGraphï¼‰ï¼š
  ChiefEditor æŒ‡æŒ¥ä¸€ç»„ä¸“ä¸š Agentï¼š
  Start â†’ Browser(åˆå§‹è°ƒç ”)
        â†’ Planner(è§„åˆ’)
        â†’ Human(äººå·¥å®¡æ ¸) â”€â”€â”
        â†’ Researcher(å¹¶è¡Œç ”ç©¶) â”‚ (æ‹’ç»åˆ™å›åˆ° Planner)
        â†’ Writer(æ’°å†™) â†â”€â”€â”€â”€â”€â”˜
        â†’ Publisher(å‘å¸ƒ) â†’ End
```

æ ¸å¿ƒæ¦‚å¿µï¼šStateGraph = çŠ¶æ€(`ResearchState`) + èŠ‚ç‚¹(Agent) + è¾¹(æµè½¬è§„åˆ™)
ä¸éœ€è¦ä¼šå†™ LangGraph ä»£ç ï¼ŒçŸ¥é“åœ¨å“ªé‡ŒåŠ èŠ‚ç‚¹å°±è¡Œã€‚

---

# ç¬¬äºŒéƒ¨åˆ†ï¼šä¸‹ä¸€æ­¥å­¦ä¹ è®¡åˆ’

---

## é˜¶æ®µ Aï¼šæç¤ºè¯å·¥ç¨‹ï¼ˆå½±å“æŠ¥å‘Šè´¨é‡çš„å¦ä¸€åŠï¼‰

> ä¸Šä¸‹æ–‡å‹ç¼©å†³å®šäº†"å–‚ä»€ä¹ˆç»™ LLM"ï¼Œæç¤ºè¯å†³å®šäº†"LLM æ€ä¹ˆå†™"

### éœ€è¦æŒæ¡çš„çŸ¥è¯†ç‚¹

- [ ] `prompts.py` çš„ç»„ç»‡ç»“æ„â€”â€”æŒ‰åŠŸèƒ½åˆ†ç±»ï¼ˆæŸ¥è¯¢è§„åˆ’/æœç´¢ä¼˜åŒ–/å†…å®¹æ‘˜è¦/æŠ¥å‘Šå†™ä½œ/å¼•ç”¨æ ¼å¼ï¼‰
- [ ] Prompt Family æœºåˆ¶â€”â€”`get_prompt_family()` å¦‚ä½•åŠ è½½ä¸åŒé£æ ¼çš„æç¤ºè¯
- [ ] æŠ¥å‘Šå†™ä½œ prompt ä¸­çš„å˜é‡æ³¨å…¥â€”â€”`{query}`ã€`{context}`ã€`{report_format}` ç­‰å ä½ç¬¦
- [ ] 15 ç§å†™ä½œè¯­è°ƒï¼ˆToneï¼‰çš„ prompt å·®å¼‚
- [ ] å¦‚ä½•è‡ªå®šä¹‰ PROMPT_FAMILY å®ç°æ•´å¥—é£æ ¼æ›¿æ¢

**AI åä½œè¯æœ¯ï¼š**
```
"å¸®æˆ‘çœ‹ prompts.py é‡Œ research_report çš„å†™ä½œ promptï¼Œ
æˆ‘æƒ³è®©æŠ¥å‘Šæ›´åå‘æ•°æ®åˆ†æé£æ ¼ï¼Œå¸®æˆ‘è°ƒæ•´ prompt æ¨¡æ¿"
```

### å®æ“ä»»åŠ¡
- [ ] ç”¨åŒä¸€ä¸ªæŸ¥è¯¢ï¼Œåˆ†åˆ«ç”¨ `--tone objective` å’Œ `--tone analytical` è·‘ä¸€éï¼Œå¯¹æ¯”è¾“å‡ºå·®å¼‚
- [ ] æ‰¾åˆ° `prompts.py` ä¸­æ§åˆ¶æŠ¥å‘Šç»“æ„çš„ promptï¼Œç†è§£å®ƒæ€ä¹ˆè¦æ±‚ LLM ç»„ç»‡å†…å®¹

---

## é˜¶æ®µ Bï¼šScraper æŠ“å–å±‚æ·±å…¥ï¼ˆè§£å†³"æŠ“ä¸åˆ°"çš„é—®é¢˜ï¼‰

> æœç´¢åˆ°äº†ä½†æŠ“ä¸ä¸‹æ¥ï¼Œæ˜¯å®é™…è¿ç»´ä¸­æœ€å¸¸é‡åˆ°çš„é—®é¢˜

### éœ€è¦æŒæ¡çš„çŸ¥è¯†ç‚¹

- [ ] `scraper/scraper.py` ä¸»è°ƒåº¦å™¨çš„åˆ†å‘é€»è¾‘
- [ ] 7 ç§ Scraper çš„é€‚ç”¨åœºæ™¯å’Œå±€é™æ€§ï¼š

| Scraper | é€‚åˆ | ä¸é€‚åˆ |
|---------|------|--------|
| `bs`ï¼ˆBeautifulSoupï¼‰ | é™æ€ HTML | JS æ¸²æŸ“çš„ SPA é¡µé¢ |
| `browser`ï¼ˆSeleniumï¼‰ | åŠ¨æ€é¡µé¢ | é€Ÿåº¦æ…¢ã€éœ€è¦ Chrome |
| `pymupdf` | PDF æ–‡æ¡£ | ç½‘é¡µ |
| `arxiv` | è®ºæ–‡ | æ™®é€šç½‘é¡µ |
| `firecrawl` | å„ç§é¡µé¢ï¼ˆäº‘æœåŠ¡ï¼‰ | éœ€ä»˜è´¹ |
| `tavily_extract` | Tavily ç”¨æˆ· | é Tavily ç”¨æˆ· |
| `web_base_loader` | LangChain ç”Ÿæ€ | ç‰¹æ®Šæ ¼å¼ |

- [ ] å¹¶å‘æ§åˆ¶ï¼š`MAX_SCRAPER_WORKERS` å’Œ `SCRAPER_RATE_LIMIT_DELAY` çš„é…åˆ
- [ ] åçˆ¬åº”å¯¹ç­–ç•¥

**AI åä½œè¯æœ¯ï¼š**
```
"æœ‰å‡ ä¸ªç½‘ç«™æ€»æ˜¯æŠ“å–å¤±è´¥ï¼Œå¸®æˆ‘åœ¨ scraper/ é‡ŒåŠ ä¸ªé™çº§ç­–ç•¥ï¼š
bs å¤±è´¥è‡ªåŠ¨æ¢ browser é‡è¯•"
```

---

## é˜¶æ®µ Cï¼šDeep Research æ·±åº¦ç ”ç©¶æ¨¡å¼ï¼ˆé«˜çº§åŠŸèƒ½ï¼‰

> Deep æ¨¡å¼æ˜¯åŒºåˆ«äºæ™®é€šç ”ç©¶çš„æ ¸å¿ƒé«˜çº§åŠŸèƒ½

### éœ€è¦æŒæ¡çš„çŸ¥è¯†ç‚¹

- [ ] `skills/deep_research.py` çš„å¤šè½®è¿­ä»£é€»è¾‘
- [ ] BREADTH Ã— DEPTH Ã— CONCURRENCY ä¸‰ä¸ªå‚æ•°çš„äº¤äº’æ•ˆæœ
- [ ] Deep æ¨¡å¼ä¸æ™®é€šæ¨¡å¼çš„æ•°æ®æµå·®å¼‚
- [ ] Deep æ¨¡å¼çš„æˆæœ¬ä¼°ç®—æ–¹æ³•

**å®æ“ä»»åŠ¡ï¼š**
- [ ] ç”¨ `--report_type deep` è·‘ä¸€æ¬¡ï¼Œè§‚å¯Ÿè¿­ä»£è¿‡ç¨‹
- [ ] å¯¹æ¯” `DEEP_RESEARCH_BREADTH=2 DEPTH=1` vs `BREADTH=4 DEPTH=3` çš„æ•ˆæœå’Œæˆæœ¬

---

## é˜¶æ®µ Dï¼šåç«¯ API ä¸ WebSocketï¼ˆWeb æœåŠ¡è¿ç»´ï¼‰

> å¦‚æœä½ é€šè¿‡ Web ç•Œé¢æä¾›æœåŠ¡ï¼Œå¿…é¡»ç†è§£è¿™ä¸€å±‚

### éœ€è¦æŒæ¡çš„çŸ¥è¯†ç‚¹

- [ ] `main.py` å’Œ `backend/server/app.py` çš„ API ç«¯ç‚¹è®¾è®¡
- [ ] WebSocket é€šä¿¡åè®®â€”â€”å‰ç«¯å¦‚ä½•å®æ—¶æ¥æ”¶ç ”ç©¶è¿›åº¦
- [ ] `backend/report_type/` ä¸‹å„æŠ¥å‘Šç±»å‹çš„åç«¯ Agent å®ç°
- [ ] æŠ¥å‘Šå­˜å‚¨æœºåˆ¶å’Œæ–‡ä»¶ä¸Šä¼ /ä¸‹è½½ç«¯ç‚¹

**AI åä½œè¯æœ¯ï¼š**
```
"å¸®æˆ‘åœ¨ backend/server/app.py é‡ŒåŠ ä¸€ä¸ª /api/health å¥åº·æ£€æŸ¥ç«¯ç‚¹"
"å¸®æˆ‘çœ‹çœ‹ WebSocket æ–­è¿åæœ‰æ²¡æœ‰è‡ªåŠ¨é‡è¿æœºåˆ¶"
```

---

## é˜¶æ®µ Eï¼šMCP åè®®é›†æˆï¼ˆæœ€çµæ´»çš„æ‰©å±•æ–¹å¼ï¼‰

> MCP æ˜¯æœªæ¥ AI å·¥å…·ç”Ÿæ€çš„æ ‡å‡†åè®®

### éœ€è¦æŒæ¡çš„çŸ¥è¯†ç‚¹

- [ ] MCP åŸºç¡€æ¦‚å¿µï¼ˆModel Context Protocolï¼‰
- [ ] 3 ç§è¿æ¥æ–¹å¼ï¼šstdio / websocket / http
- [ ] `mcp/client.py` çš„è¿æ¥ç®¡ç†
- [ ] `mcp/tool_selector.py` çš„ LLM è¾…åŠ©å·¥å…·é€‰æ‹©
- [ ] 3 ç§ç­–ç•¥ï¼šfastï¼ˆç”¨ä¸€æ¬¡ï¼‰/ deepï¼ˆæ¯ä¸ªå­æŸ¥è¯¢éƒ½ç”¨ï¼‰/ disabled
- [ ] å¦‚ä½•å†™ä¸€ä¸ª MCP Server æ¥å…¥è‡ªæœ‰æ•°æ®æº

**AI åä½œè¯æœ¯ï¼š**
```
"å¸®æˆ‘å†™ä¸€ä¸ª MCP Serverï¼Œæ¥å…¥å…¬å¸çš„ Confluence Wikiï¼Œ
è®© GPT-Researcher å¯ä»¥æœç´¢å†…éƒ¨çŸ¥è¯†åº“"
```

---

## é˜¶æ®µ Fï¼šGit Fork ç»´æŠ¤ä¸ä¸Šæ¸¸åŒæ­¥

### éœ€è¦æŒæ¡çš„çŸ¥è¯†ç‚¹

- [ ] Fork åˆ†æ”¯ç­–ç•¥ï¼šupstream/master â† origin/master â† feature/*
- [ ] `git remote add upstream` + `git fetch upstream` + `git merge`
- [ ] ç†è§£ä½ æ”¹åŠ¨æœ€å¤šçš„æ–‡ä»¶å°±æ˜¯å†²çªé«˜å‘åŒº
- [ ] é€šè¿‡ `git diff upstream/master..HEAD` æŸ¥çœ‹ä½ æ‰€æœ‰çš„è‡ªå®šä¹‰æ”¹åŠ¨

---

## å­¦ä¹ è·¯çº¿å›¾æ€»è§ˆ

```
å·²å®Œæˆ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  âœ… ä¸€ã€æ¶æ„åœ°å›¾ï¼ˆæ•°æ®æµ + æ¨¡å—é€ŸæŸ¥ + agent.py æ ¸å¿ƒé€»è¾‘ï¼‰
  âœ… äºŒã€é…ç½®å³æ§åˆ¶ï¼ˆé…ç½®ç³»ç»Ÿ + å®éªŒæ‰‹å†Œï¼‰
  âœ… ä¸‰ã€ä¸Šä¸‹æ–‡å‹ç¼©ï¼ˆåˆ†å—â†’å‘é‡è¿‡æ»¤â†’è¾“å‡º ä¸‰æ­¥ç®¡é“ï¼‰
  âœ… å››ã€æ•…éšœæ’æŸ¥ï¼ˆ6 ä¸ªå®æˆ˜åœºæ™¯ + æ’æŸ¥æ–¹æ³•è®ºï¼‰
  âœ… äº”ã€AI åä½œå…ƒæŠ€èƒ½ï¼ˆPrompt æ¨¡æ¿ + éªŒè¯æ¸…å•ï¼‰

ä¸‹ä¸€æ­¥ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  â¬œ A. æç¤ºè¯å·¥ç¨‹         â†’ å½±å“æŠ¥å‘Šå†™ä½œè´¨é‡     [P1 å»ºè®®ä¸‹ä¸€ä¸ªå­¦]
  â¬œ B. Scraper æŠ“å–å±‚æ·±å…¥  â†’ è§£å†³"æŠ“ä¸åˆ°"       [P1 å®é™…è¿ç»´é«˜é¢‘]
  â¬œ C. Deep Research æ¨¡å¼  â†’ é«˜çº§åŠŸèƒ½           [P2]
  â¬œ D. åç«¯ API / WebSocket â†’ Web æœåŠ¡è¿ç»´      [P2]
  â¬œ E. MCP åè®®é›†æˆ        â†’ æœ€çµæ´»çš„æ‰©å±•       [P2]
  â¬œ F. Git Fork ç»´æŠ¤       â†’ æŒç»­è¿ç»´           [P2]
```

---

## å¿«é€Ÿå‚è€ƒå¡ç‰‡

### ç›®å½•å®šä½é€Ÿè®°

```
è¦æ”¹æœç´¢ï¼Ÿ     â†’ gpt_researcher/retrievers/
è¦æ”¹æŠ“å–ï¼Ÿ     â†’ gpt_researcher/scraper/
è¦æ”¹æç¤ºè¯ï¼Ÿ   â†’ gpt_researcher/prompts.py
è¦æ”¹é…ç½®ï¼Ÿ     â†’ .env æˆ– gpt_researcher/config/
è¦æ”¹ LLMï¼Ÿ    â†’ gpt_researcher/llm_provider/
è¦æ”¹ APIï¼Ÿ    â†’ backend/server/
è¦æ”¹æµç¨‹ï¼Ÿ     â†’ gpt_researcher/agent.py
è¦åŠ  Agentï¼Ÿ  â†’ multi_agents/agents/
è¦åŠ  MCPï¼Ÿ    â†’ gpt_researcher/mcp/
```

### å…³é”®ç¯å¢ƒå˜é‡

```bash
# === å¿…é¡» ===
OPENAI_API_KEY=xxx
TAVILY_API_KEY=xxx

# === LLMï¼ˆæˆæœ¬æ§åˆ¶æ ¸å¿ƒï¼‰===
FAST_LLM=openai:gpt-4o-mini
SMART_LLM=openai:gpt-4.1
STRATEGIC_LLM=openai:o4-mini

# === æœç´¢ä¸æŠ“å– ===
RETRIEVER=tavily
SCRAPER=bs
MAX_SEARCH_RESULTS_PER_QUERY=5
MAX_SCRAPER_WORKERS=15

# === æŠ¥å‘Š ===
REPORT_TYPE=research_report
TOTAL_WORDS=1200
LANGUAGE=english
TEMPERATURE=0.4

# === å‹ç¼©ï¼ˆæŠ¥å‘Šè´¨é‡å…³é”®ï¼‰===
SIMILARITY_THRESHOLD=0.35
EMBEDDING=openai:text-embedding-3-small

# === è°ƒè¯• ===
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=xxx
```

### ä¸ƒç§æŠ¥å‘Šç±»å‹

| ç±»å‹ | ç”¨é€” | ä½•æ—¶é€‰ |
|------|------|--------|
| `research_report` | æ ‡å‡†ç»¼åˆæŠ¥å‘Š | é»˜è®¤ |
| `detailed_report` | æ·±åº¦åˆ†æ | éœ€è¦è¯¦å°½åˆ†æ |
| `deep` | å¤šè½®æ·±åº¦ç ”ç©¶ | å¤æ‚è¯¾é¢˜æ·±æŒ– |
| `outline_report` | ç»“æ„å¤§çº² | å¿«é€Ÿäº†è§£æ¡†æ¶ |
| `resource_report` | èµ„æºæ¸…å• | æ”¶é›†å‚è€ƒèµ„æ–™ |
| `subtopic_report` | å­ä¸»é¢˜èšç„¦ | ä¸“æ³¨ç»†åˆ†æ–¹å‘ |
| `custom_report` | ç”¨æˆ·è‡ªå®šä¹‰ | ç‰¹æ®Šæ ¼å¼è¦æ±‚ |

### 14 ç§æœç´¢å¼•æ“

| å…è´¹ | ä»˜è´¹ |
|------|------|
| duckduckgo, arxiv, semantic_scholar, pubmed_central | tavily(é»˜è®¤), google, serpapi, serper, bing, exa, searchapi |
| searx(éœ€è‡ªå»º) | custom(è‡ªå®šä¹‰), mcp(åè®®æ‰©å±•) |
